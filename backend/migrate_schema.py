#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞–º–∏
"""

import os
import sqlite3
from datetime import datetime
from pathlib import Path

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

class DatabaseMigration:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, database_url: str = "sqlite:///./patients.db"):
        self.database_url = database_url
        self.engine = create_engine(database_url)
        
    def create_backup(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        db_path = Path("patients.db")
        if not db_path.exists():
            print("–§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return ""
            
        backup_dir = Path("backups")
        backup_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_filename = f"backup_pre_file_migration_{timestamp}.db"
        backup_path = backup_dir / backup_filename
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        import shutil
        shutil.copy2(db_path, backup_path)
        print(f"–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
        return str(backup_path)
    
    def check_current_schema(self) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—É—â—É—é —Å—Ö–µ–º—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        with sqlite3.connect("patients.db") as conn:
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–±–ª–∏—Ü–∞—Ö
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            schema_info = {
                'tables': tables,
                'files_table_exists': 'files' in tables,
                'file_versions_table_exists': 'file_versions' in tables
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã files
            if 'files' in tables:
                cursor.execute("PRAGMA table_info(files)")
                files_columns = cursor.fetchall()
                schema_info['files_columns'] = [col[1] for col in files_columns]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π
                expected_columns = [
                    'medical_file_type', 'medical_category', 'study_date', 
                    'body_part', 'image_orientation', 'file_size', 'mime_type', 'file_hash'
                ]
                existing_columns = [col[1] for col in files_columns]
                
                schema_info['missing_files_columns'] = [col for col in expected_columns if col not in existing_columns]
                schema_info['has_old_file_type'] = 'file_type' in existing_columns
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã file_versions
            if 'file_versions' in tables:
                cursor.execute("PRAGMA table_info(file_versions)")
                version_columns = cursor.fetchall()
                schema_info['version_columns'] = [col[1] for col in version_columns]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π
                expected_version_columns = [
                    'file_hash', 'file_size', 'version_type', 
                    'version_description', 'created_by'
                ]
                existing_version_columns = [col[1] for col in version_columns]
                
                schema_info['missing_version_columns'] = [col for col in expected_version_columns if col not in existing_version_columns]
            
            return schema_info
    
    def migrate_files_table(self, dry_run: bool = True) -> list:
        """–ú–∏–≥—Ä–∏—Ä—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É files"""
        print(f"–ú–∏–≥—Ä–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã files (dry_run={dry_run})...")
        
        schema_info = self.check_current_schema()
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å—Ç–∞—Ä–æ–≥–æ –ø–æ–ª—è file_type, –º–∏–≥—Ä–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞
        if not schema_info['has_old_file_type']:
            print("–¢–∞–±–ª–∏—Ü–∞ files —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–æ–≤—É—é —Å—Ö–µ–º—É –∏–ª–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –º–∏–≥—Ä–∞—Ü–∏–∏")
            return []
        
        migration_steps = []
        
        # 1. –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü—É files
        files_migrations = {
            'medical_file_type': 'ALTER TABLE files ADD COLUMN medical_file_type TEXT;',
            'medical_category': 'ALTER TABLE files ADD COLUMN medical_category TEXT;',
            'study_date': 'ALTER TABLE files ADD COLUMN study_date DATE;',
            'body_part': 'ALTER TABLE files ADD COLUMN body_part TEXT(100);',
            'image_orientation': 'ALTER TABLE files ADD COLUMN image_orientation TEXT(50);',
            'file_size': 'ALTER TABLE files ADD COLUMN file_size INTEGER;',
            'mime_type': 'ALTER TABLE files ADD COLUMN mime_type TEXT(100);',
            'file_hash': 'ALTER TABLE files ADD COLUMN file_hash TEXT(64);'
        }
        
        for column, sql in files_migrations.items():
            if column in schema_info['missing_files_columns']:
                migration_steps.append({
                    'table': 'files',
                    'sql': sql,
                    'description': f'–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ {column}'
                })
        
        # 2. –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ file_type –≤ –Ω–æ–≤—ã–π medical_file_type
        copy_data_sql = """
            UPDATE files 
            SET medical_file_type = CASE file_type
                WHEN 'image' THEN 'photo'
                WHEN 'pdf' THEN 'pdf'  
                WHEN 'document' THEN 'document'
                WHEN 'other' THEN 'other'
                ELSE 'other'
            END
            WHERE medical_file_type IS NULL;
        """
        
        migration_steps.append({
            'table': 'files',
            'sql': copy_data_sql,
            'description': '–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ file_type –≤ medical_file_type'
        })
        
        # 3. –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π
        index_sqls = [
            "CREATE INDEX IF NOT EXISTS idx_files_medical_type ON files(medical_file_type);",
            "CREATE INDEX IF NOT EXISTS idx_files_medical_category ON files(medical_category);",
            "CREATE INDEX IF NOT EXISTS idx_files_study_date ON files(study_date);",
            "CREATE INDEX IF NOT EXISTS idx_files_patient_type ON files(patient_id, medical_file_type);"
        ]
        
        for sql in index_sqls:
            migration_steps.append({
                'table': 'files',
                'sql': sql,
                'description': '–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞'
            })
        
        return migration_steps
    
    def migrate_file_versions_table(self, dry_run: bool = True) -> list:
        """–ú–∏–≥—Ä–∏—Ä—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É file_versions"""
        print(f"–ú–∏–≥—Ä–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã file_versions (dry_run={dry_run})...")
        
        schema_info = self.check_current_schema()
        migration_steps = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü—É file_versions
        version_migrations = {
            'file_hash': 'ALTER TABLE file_versions ADD COLUMN file_hash TEXT(64);',
            'file_size': 'ALTER TABLE file_versions ADD COLUMN file_size INTEGER;',
            'version_type': 'ALTER TABLE file_versions ADD COLUMN version_type TEXT DEFAULT "baseline";',
            'version_description': 'ALTER TABLE file_versions ADD COLUMN version_description TEXT;',
            'created_by': 'ALTER TABLE file_versions ADD COLUMN created_by INTEGER;'
        }
        
        for column, sql in version_migrations.items():
            if column in schema_info['missing_version_columns']:
                migration_steps.append({
                    'table': 'file_versions',
                    'sql': sql,
                    'description': f'–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ {column}'
                })
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤–µ—Ä—Å–∏–∏ –∫–∞–∫ baseline
        update_versions_sql = """
            UPDATE file_versions 
            SET version_type = 'baseline'
            WHERE version_type IS NULL OR version_type = '';
        """
        
        migration_steps.append({
            'table': 'file_versions',
            'sql': update_versions_sql,
            'description': '–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–µ—Ä—Å–∏–π –∫–∞–∫ baseline'
        })
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
        index_sqls = [
            "CREATE INDEX IF NOT EXISTS idx_file_versions_type ON file_versions(version_type);",
            "CREATE INDEX IF NOT EXISTS idx_file_versions_file_id ON file_versions(file_id);"
        ]
        
        for sql in index_sqls:
            migration_steps.append({
                'table': 'file_versions',
                'sql': sql,
                'description': '–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞'
            })
        
        return migration_steps
    
    def add_user_relationships(self, dry_run: bool = True) -> list:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –≤–Ω–µ—à–Ω–∏–µ –∫–ª—é—á–∏ –¥–ª—è —Å–≤—è–∑–µ–π —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏"""
        print(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–≤—è–∑–µ–π —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ (dry_run={dry_run})...")
        
        migration_steps = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–Ω–µ—à–Ω–∏–π –∫–ª—é—á –¥–ª—è created_by –≤ file_versions
        fk_sql = """
            CREATE INDEX IF NOT EXISTS idx_file_versions_created_by 
            ON file_versions(created_by);
        """
        
        migration_steps.append({
            'table': 'file_versions',
            'sql': fk_sql,
            'description': '–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è —Å–≤—è–∑–∏ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏'
        })
        
        return migration_steps
    
    def execute_migrations(self, migration_steps: list, dry_run: bool = True) -> dict:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –º–∏–≥—Ä–∞—Ü–∏—é"""
        results = {
            'executed': [],
            'errors': [],
            'skipped': []
        }
        
        if dry_run:
            print("–†–ï–ñ–ò–ú DRY RUN - –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
        
        for step in migration_steps:
            try:
                if dry_run:
                    results['skipped'].append(step['description'])
                    print(f"  [SKIP] {step['description']}")
                else:
                    with sqlite3.connect("patients.db") as conn:
                        conn.execute(step['sql'])
                        conn.commit()
                        results['executed'].append(step['description'])
                        print(f"  [OK] {step['description']}")
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏: {step['description']} - {str(e)}"
                results['errors'].append(error_msg)
                print(f"  [ERROR] {error_msg}")
        
        return results
    
    def run_full_migration(self, dry_run: bool = True) -> dict:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é –º–∏–≥—Ä–∞—Ü–∏—é —Å—Ö–µ–º—ã"""
        print("=== –ù–ê–ß–ê–õ–û –ú–ò–ì–†–ê–¶–ò–ò –°–•–ï–ú–´ –ë–î ===")
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
        print("\n1. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏...")
        backup_path = self.create_backup()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ö–µ–º—É
        print("\n2. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π —Å—Ö–µ–º—ã...")
        schema_info = self.check_current_schema()
        print(f"–¢–∞–±–ª–∏—Ü—ã –≤ –ë–î: {', '.join(schema_info['tables'])}")
        print(f"–¢–∞–±–ª–∏—Ü–∞ files: {'–µ—Å—Ç—å' if schema_info['files_table_exists'] else '–Ω–µ—Ç'}")
        print(f"–¢–∞–±–ª–∏—Ü–∞ file_versions: {'–µ—Å—Ç—å' if schema_info['file_versions_table_exists'] else '–Ω–µ—Ç'}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏
        print("\n3. –ü–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏...")
        all_steps = []
        
        if schema_info['files_table_exists']:
            files_steps = self.migrate_files_table(dry_run=True)
            all_steps.extend(files_steps)
            print(f"–®–∞–≥–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã files: {len(files_steps)}")
        
        if schema_info['file_versions_table_exists']:
            version_steps = self.migrate_file_versions_table(dry_run=True)
            all_steps.extend(version_steps)
            print(f"–®–∞–≥–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã file_versions: {len(version_steps)}")
        
        user_steps = self.add_user_relationships(dry_run=True)
        all_steps.extend(user_steps)
        print(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —à–∞–≥–æ–≤: {len(user_steps)}")
        print(f"–í—Å–µ–≥–æ —à–∞–≥–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏: {len(all_steps)}")
        
        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if not dry_run:
            confirm = input(f"\n–ü—Ä–∏–º–µ–Ω–∏—Ç—å {len(all_steps)} –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö? (y/N): ")
            if confirm.lower() != 'y':
                print("–ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                return {'cancelled': True}
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é
        print(f"\n4. {'–ü—Ä–æ–≤–µ—Ä–∫–∞' if dry_run else '–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ'} –º–∏–≥—Ä–∞—Ü–∏–∏...")
        results = self.execute_migrations(all_steps, dry_run)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        print("\n5. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–µ–º—ã...")
        final_schema = self.check_current_schema()
        
        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
        print("\n=== –ò–¢–û–ì–ò –ú–ò–ì–†–ê–¶–ò–ò ===")
        print(f"–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_path}")
        print(f"–®–∞–≥–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {len(results['executed'])}")
        print(f"–®–∞–≥–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {len(results['skipped'])}")
        print(f"–û—à–∏–±–æ–∫: {len(results['errors'])}")
        
        if results['errors']:
            print("\n–û–®–ò–ë–ö–ò:")
            for error in results['errors']:
                print(f"  - {error}")
        
        print(f"\n–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {backup_path}")
        
        return {
            'backup_path': backup_path,
            'steps_planned': len(all_steps),
            'steps_executed': len(results['executed']),
            'errors': results['errors'],
            'schema_info': final_schema
        }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã —Ñ–∞–π–ª–æ–≤')
    parser.add_argument('--dry-run', action='store_true', 
                       help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏ –±–µ–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π')
    parser.add_argument('--force', action='store_true',
                       help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é –±–µ–∑ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è')
    
    args = parser.parse_args()
    
    migration = DatabaseMigration()
    
    if args.force and not args.dry_run:
        dry_run = False
    else:
        dry_run = args.dry_run
    
    try:
        results = migration.run_full_migration(dry_run)
        
        if not dry_run and not results.get('cancelled'):
            print("\n‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ö–µ–º—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        elif dry_run:
            print("\nüìã –ü–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤. –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–∑ --dry-run")
        else:
            print("\n‚ùå –ú–∏–≥—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –∏–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
            
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())